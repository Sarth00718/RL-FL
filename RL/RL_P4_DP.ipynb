{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce5b13b2",
   "metadata": {},
   "source": [
    "# Gridworld Reinforcement Learning\n",
    "\n",
    "## Problem Description\n",
    "- 4x4 Gridworld with states {0 ... 15}\n",
    "- Terminal State = 9\n",
    "- Actions = Up, Down, Left, Right\n",
    "- Reward = -1 per step\n",
    "- Discount Factor = 0.8\n",
    "- Initial Value = -1 for all states except terminal\n",
    "\n",
    "This notebook implements:\n",
    "1. Iterative Policy Evaluation\n",
    "2. Greedy Policy Extraction\n",
    "3. Value Iteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ff286b",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43fb7299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b9e930",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a78158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 4\n",
    "gamma = 0.8\n",
    "terminal_state = 9\n",
    "actions = ['up','down','left','right']\n",
    "num_states = grid_size * grid_size\n",
    "\n",
    "def next_state(state, action):\n",
    "    row, col = divmod(state, grid_size)\n",
    "\n",
    "    if action == 'up':\n",
    "        row = max(row - 1, 0)\n",
    "    elif action == 'down':\n",
    "        row = min(row + 1, grid_size - 1)\n",
    "    elif action == 'left':\n",
    "        col = max(col - 1, 0)\n",
    "    elif action == 'right':\n",
    "        col = min(col + 1, grid_size - 1)\n",
    "\n",
    "    return row * grid_size + col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ea291d",
   "metadata": {},
   "source": [
    "## Initialize Value Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d17988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = -1 * np.ones(num_states)\n",
    "V[terminal_state] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af19301c",
   "metadata": {},
   "source": [
    "## 1. Iterative Policy Evaluation (Equiprobable Random Policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eafbaeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "[[-1.8 -1.8 -1.8 -1.8]\n",
      " [-1.8 -1.6 -1.8 -1.8]\n",
      " [-1.6  0.  -1.6 -1.8]\n",
      " [-1.8 -1.6 -1.8 -1.8]]\n",
      "Iteration 2\n",
      "[[-2.44 -2.4  -2.44 -2.44]\n",
      " [-2.36 -2.08 -2.36 -2.44]\n",
      " [-2.04  0.   -2.08 -2.4 ]\n",
      " [-2.36 -2.04 -2.36 -2.44]]\n",
      "Iteration 3\n",
      "[[-2.928 -2.872 -2.928 -2.952]\n",
      " [-2.784 -2.424 -2.808 -2.928]\n",
      " [-2.352  0.    -2.424 -2.872]\n",
      " [-2.76  -2.352 -2.784 -2.928]]\n"
     ]
    }
   ],
   "source": [
    "def policy_evaluation(V, iterations=3):\n",
    "    for k in range(iterations):\n",
    "        new_V = V.copy()\n",
    "\n",
    "        for s in range(num_states):\n",
    "            if s == terminal_state:\n",
    "                continue\n",
    "\n",
    "            value = 0\n",
    "            for a in actions:\n",
    "                ns = next_state(s, a)\n",
    "                reward = -1\n",
    "                value += 0.25 * (reward + gamma * V[ns])\n",
    "\n",
    "            new_V[s] = value\n",
    "\n",
    "        V = new_V\n",
    "        print(f'Iteration {k+1}')\n",
    "        print(V.reshape(grid_size, grid_size))\n",
    "\n",
    "    return V\n",
    "\n",
    "V_policy = policy_evaluation(V.copy(), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8849302",
   "metadata": {},
   "source": [
    "## 2. Greedy Policy Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24a7ef22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy Policy from Policy Evaluation:\n",
      "[['down' 'down' 'down' 'down']\n",
      " ['down' 'down' 'down' 'left']\n",
      " ['right' 'T' 'left' 'left']\n",
      " ['up' 'up' 'left' 'left']]\n"
     ]
    }
   ],
   "source": [
    "def greedy_policy(V):\n",
    "    policy = [''] * num_states\n",
    "\n",
    "    for s in range(num_states):\n",
    "        if s == terminal_state:\n",
    "            policy[s] = 'T'\n",
    "            continue\n",
    "\n",
    "        best_action = None\n",
    "        best_value = -np.inf\n",
    "\n",
    "        for a in actions:\n",
    "            ns = next_state(s, a)\n",
    "            value = -1 + gamma * V[ns]\n",
    "\n",
    "            if value > best_value:\n",
    "                best_value = value\n",
    "                best_action = a\n",
    "\n",
    "        policy[s] = best_action\n",
    "\n",
    "    return np.array(policy).reshape(grid_size, grid_size)\n",
    "\n",
    "print('Greedy Policy from Policy Evaluation:')\n",
    "print(greedy_policy(V_policy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d699fa9",
   "metadata": {},
   "source": [
    "## 3. Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "356a2b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Iteration 1\n",
      "[[-1.8 -1.8 -1.8 -1.8]\n",
      " [-1.8 -1.  -1.8 -1.8]\n",
      " [-1.   0.  -1.  -1.8]\n",
      " [-1.8 -1.  -1.8 -1.8]]\n",
      "Value Iteration 2\n",
      "[[-2.44 -1.8  -2.44 -2.44]\n",
      " [-1.8  -1.   -1.8  -2.44]\n",
      " [-1.    0.   -1.   -1.8 ]\n",
      " [-1.8  -1.   -1.8  -2.44]]\n",
      "Value Iteration 3\n",
      "[[-2.44  -1.8   -2.44  -2.952]\n",
      " [-1.8   -1.    -1.8   -2.44 ]\n",
      " [-1.     0.    -1.    -1.8  ]\n",
      " [-1.8   -1.    -1.8   -2.44 ]]\n"
     ]
    }
   ],
   "source": [
    "def value_iteration(iterations=3):\n",
    "    V = -1 * np.ones(num_states)\n",
    "    V[terminal_state] = 0\n",
    "\n",
    "    for k in range(iterations):\n",
    "        new_V = V.copy()\n",
    "\n",
    "        for s in range(num_states):\n",
    "            if s == terminal_state:\n",
    "                continue\n",
    "\n",
    "            values = []\n",
    "            for a in actions:\n",
    "                ns = next_state(s, a)\n",
    "                values.append(-1 + gamma * V[ns])\n",
    "\n",
    "            new_V[s] = max(values)\n",
    "\n",
    "        V = new_V\n",
    "        print(f'Value Iteration {k+1}')\n",
    "        print(V.reshape(grid_size, grid_size))\n",
    "\n",
    "    return V\n",
    "\n",
    "V_opt = value_iteration(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9758a150",
   "metadata": {},
   "source": [
    "## Optimal Policy from Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea722eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Policy:\n",
      "[['down' 'down' 'down' 'down']\n",
      " ['down' 'down' 'down' 'down']\n",
      " ['right' 'T' 'left' 'left']\n",
      " ['up' 'up' 'up' 'up']]\n"
     ]
    }
   ],
   "source": [
    "print('Optimal Policy:')\n",
    "print(greedy_policy(V_opt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
