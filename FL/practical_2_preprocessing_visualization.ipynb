{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 2: Data Preprocessing and Visualization\n",
    "## Diabetic Retinopathy Image Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('dataset_info.csv'):\n",
    "    df = pd.read_csv('dataset_info.csv')\n",
    "    print(f\"Dataset loaded: {len(df)} images\")\n",
    "else:\n",
    "    dataset_path = 'colored_images/colored_images/'\n",
    "    categories = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "    \n",
    "    data = []\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(dataset_path, category)\n",
    "        images = [f for f in os.listdir(category_path) if f.endswith('.png')]\n",
    "        \n",
    "        for img_name in images:\n",
    "            img_path = os.path.join(category_path, img_name)\n",
    "            eye_side = 'left' if 'left' in img_name else 'right'\n",
    "            patient_id = img_name.split('_')[0]\n",
    "            \n",
    "            data.append({\n",
    "                'filename': img_name,\n",
    "                'filepath': img_path,\n",
    "                'category': category,\n",
    "                'patient_id': patient_id,\n",
    "                'eye_side': eye_side\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"Dataset created: {len(df)} images\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Cleaning - Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values in dataset:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nTotal missing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extract Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = min(200, len(df))\n",
    "sample_df = df.sample(n=sample_size, random_state=42).copy()\n",
    "\n",
    "features = []\n",
    "for idx, row in sample_df.iterrows():\n",
    "    try:\n",
    "        img = Image.open(row['filepath'])\n",
    "        img_array = np.array(img)\n",
    "        \n",
    "        features.append({\n",
    "            'width': img.width,\n",
    "            'height': img.height,\n",
    "            'mean_red': img_array[:,:,0].mean(),\n",
    "            'mean_green': img_array[:,:,1].mean(),\n",
    "            'mean_blue': img_array[:,:,2].mean(),\n",
    "            'std_red': img_array[:,:,0].std(),\n",
    "            'std_green': img_array[:,:,1].std(),\n",
    "            'std_blue': img_array[:,:,2].std(),\n",
    "            'brightness': img_array.mean()\n",
    "        })\n",
    "    except:\n",
    "        features.append({k: np.nan for k in ['width', 'height', 'mean_red', 'mean_green', 'mean_blue', 'std_red', 'std_green', 'std_blue', 'brightness']})\n",
    "\n",
    "features_df = pd.DataFrame(features)\n",
    "sample_df = pd.concat([sample_df.reset_index(drop=True), features_df], axis=1)\n",
    "\n",
    "print(f\"Features extracted for {len(sample_df)} images\")\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handle Missing Values and Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values after feature extraction:\")\n",
    "print(sample_df.isnull().sum())\n",
    "\n",
    "numeric_cols = ['width', 'height', 'mean_red', 'mean_green', 'mean_blue', 'std_red', 'std_green', 'std_blue', 'brightness']\n",
    "for col in numeric_cols:\n",
    "    if sample_df[col].isnull().any():\n",
    "        sample_df[col].fillna(sample_df[col].median(), inplace=True)\n",
    "\n",
    "print(\"\\nMissing values after filling:\")\n",
    "print(sample_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return len(outliers)\n",
    "\n",
    "print(\"Outliers detected:\")\n",
    "for col in ['brightness', 'mean_red', 'mean_green', 'mean_blue']:\n",
    "    outlier_count = detect_outliers(sample_df, col)\n",
    "    print(f\"{col}: {outlier_count} outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Data Visualization - Distribution Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "category_counts = df['category'].value_counts()\n",
    "sns.barplot(x=category_counts.index, y=category_counts.values, palette='viridis')\n",
    "plt.title('Distribution of Images Across Categories', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Category', fontsize=12)\n",
    "plt.ylabel('Number of Images', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "for i, v in enumerate(category_counts.values):\n",
    "    plt.text(i, v + 10, str(v), ha='center', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "eye_counts = df['eye_side'].value_counts()\n",
    "plt.pie(eye_counts.values, labels=eye_counts.index, autopct='%1.1f%%', startangle=90, colors=['#ff9999','#66b3ff'])\n",
    "plt.title('Distribution of Left vs Right Eye Images', fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Feature Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=sample_df, x='category', y='brightness', palette='Set2')\n",
    "plt.title('Brightness Distribution by Category', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Category', fontsize=12)\n",
    "plt.ylabel('Brightness', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "sns.histplot(sample_df['mean_red'], kde=True, color='red', ax=axes[0])\n",
    "axes[0].set_title('Red Channel Distribution', fontweight='bold')\n",
    "axes[0].set_xlabel('Mean Red Value')\n",
    "\n",
    "sns.histplot(sample_df['mean_green'], kde=True, color='green', ax=axes[1])\n",
    "axes[1].set_title('Green Channel Distribution', fontweight='bold')\n",
    "axes[1].set_xlabel('Mean Green Value')\n",
    "\n",
    "sns.histplot(sample_df['mean_blue'], kde=True, color='blue', ax=axes[2])\n",
    "axes[2].set_title('Blue Channel Distribution', fontweight='bold')\n",
    "axes[2].set_xlabel('Mean Blue Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "correlation_cols = ['mean_red', 'mean_green', 'mean_blue', 'std_red', 'std_green', 'std_blue', 'brightness']\n",
    "correlation_matrix = sample_df[correlation_cols].corr()\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f', square=True, linewidths=1)\n",
    "plt.title('Feature Correlation Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_to_scale = ['mean_red', 'mean_green', 'mean_blue', 'std_red', 'std_green', 'std_blue', 'brightness']\n",
    "\n",
    "sample_df[features_to_scale] = scaler.fit_transform(sample_df[features_to_scale])\n",
    "\n",
    "print(\"Features scaled successfully!\")\n",
    "print(\"\\nScaled feature statistics:\")\n",
    "print(sample_df[features_to_scale].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_category = LabelEncoder()\n",
    "le_eye = LabelEncoder()\n",
    "\n",
    "sample_df['category_encoded'] = le_category.fit_transform(sample_df['category'])\n",
    "sample_df['eye_side_encoded'] = le_eye.fit_transform(sample_df['eye_side'])\n",
    "\n",
    "print(\"Category encoding:\")\n",
    "for i, cat in enumerate(le_category.classes_):\n",
    "    print(f\"{cat}: {i}\")\n",
    "\n",
    "print(\"\\nEye side encoding:\")\n",
    "for i, eye in enumerate(le_eye.classes_):\n",
    "    print(f\"{eye}: {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('preprocessed_data.csv', index=False)\n",
    "print(\"Preprocessed data saved to 'preprocessed_data.csv'\")\n",
    "print(f\"\\nFinal dataset shape: {sample_df.shape}\")\n",
    "print(f\"Columns: {list(sample_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DATA PREPROCESSING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total images processed: {len(sample_df)}\")\n",
    "print(f\"Features extracted: {len(features_to_scale)}\")\n",
    "print(f\"Missing values handled: Yes\")\n",
    "print(f\"Outliers detected: Yes\")\n",
    "print(f\"Feature scaling applied: StandardScaler\")\n",
    "print(f\"Label encoding applied: Yes\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
